{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO21kPwHsCdYnXKl3FW4Czw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariiaZimokha/notebooks/blob/main/decision_tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation"
      ],
      "metadata": {
        "id": "X8uHaq92Cwzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def get_data():\n",
        "  df = load_iris()\n",
        "  x = df.data\n",
        "  y = df.target\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "XjrLmrWdaKJS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, X_test, y, y_test = get_data()"
      ],
      "metadata": {
        "id": "A8Fl5ANiarVw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "  def __init__(self, value=None):\n",
        "    self.value = value\n",
        "    self.left = None\n",
        "    self.right = None\n",
        "    self.feature = None\n",
        "    self.label = None"
      ],
      "metadata": {
        "id": "nn0y3xz6Cys1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreeCl:\n",
        "  def __init__(self, max_depth=3) -> None:\n",
        "      self.root = Node()\n",
        "      self.max_depth = max_depth\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.root = self._build_tree(X, y, 0, self.root)\n",
        "  \n",
        "  def _build_tree(self, X, y, depth, node):\n",
        "    if self.max_depth <= depth or len(np.unique(y)) == 1:\n",
        "      unique_labels, counts = np.unique(y, return_counts=True)\n",
        "      node.label = unique_labels[np.argmax(counts)]\n",
        "      return node\n",
        "\n",
        "    best_column, best_value = self._get_split(X, y)\n",
        "\n",
        "    left_split_X, left_split_y, right_split_X, right_split_y = self._split_df(X, y, best_value, best_column)\n",
        "\n",
        "    node.value = best_value\n",
        "    node.feature = best_column\n",
        "\n",
        "    node.left = self._build_tree(left_split_X, left_split_y, depth + 1, Node())    \n",
        "    node.right = self._build_tree(right_split_X, right_split_y, depth + 1, Node())\n",
        "    \n",
        "    return node\n",
        "\n",
        "  def _get_split(self, X, y):\n",
        "    best_column = None\n",
        "    best_value = None\n",
        "    best_gini = float('inf')\n",
        "\n",
        "    best_gain = 0\n",
        "\n",
        "    columns = X.shape[1]\n",
        "    # for each column in the data (ot for each feature), \n",
        "    for column_index in range(columns):\n",
        "      # we find all unique velues for it \n",
        "      unique_values = np.unique(X[:, column_index])\n",
        "      # create new split for each of the value and calculate the gini impurity\n",
        "      # The feature and value with the lowest impurity, will be returned\n",
        "      for value in unique_values:\n",
        "        left_split_X, left_split_y, right_split_X, right_split_y = self._split_df(X, y, value, column_index)\n",
        "\n",
        "        # Gini impirity calculates: \n",
        "        # gini_left * lenght_left_split/total_lenght + gini_right * lenght_right_split/total_lenght\n",
        "        gini_impurity = self._gini(left_split_y) * len(left_split_y)/len(y) + self._gini(right_split_y) * len(right_split_y)/len(y)\n",
        "        \n",
        "        # the smaller gini impurity the better\n",
        "        if gini_impurity < best_gini: \n",
        "          best_gini = gini_impurity\n",
        "          best_column = column_index\n",
        "          best_value = value\n",
        "\n",
        "\n",
        "    return best_column, best_value\n",
        "\n",
        "  def _gini(self, y):\n",
        "    # We need to calculate probability for each target value in the split\n",
        "    # 1 - sum(P(colums)^2)\n",
        "    _, counts = np.unique(y, return_counts=True)\n",
        "    probabilities = counts / len(y)\n",
        "    gini = 1 - np.sum(probabilities**2)\n",
        "    return gini\n",
        "\n",
        "    # p = 0\n",
        "    # unique_targets = np.unique(y)\n",
        "    # for target_val in unique_targets:\n",
        "    #   count_val = np.sum(y == target_val)\n",
        "    #   p += (count_val/len(y))**2\n",
        "    # return 1 - p\n",
        "\n",
        "  def _split_df(self, X, y, threshold, cln_index):\n",
        "    left_split_mask = X[:, cln_index] <= threshold\n",
        "    right_split_mask = X[:, cln_index] > threshold\n",
        "\n",
        "    left_split_X = X[left_split_mask]\n",
        "    left_split_y = y[left_split_mask]\n",
        "\n",
        "    right_split_X = X[right_split_mask]\n",
        "    right_split_y = y[right_split_mask]\n",
        "\n",
        "    return left_split_X, left_split_y, right_split_X, right_split_y\n",
        "\n",
        "\n",
        "  def _predict_traverse(self, row, node):\n",
        "    if node.label is not None:\n",
        "        return node.label\n",
        "\n",
        "    column = node.feature\n",
        "\n",
        "    if row[column] <= node.value:\n",
        "        return self._predict_traverse(row, node.left)\n",
        "    else:\n",
        "        return self._predict_traverse(row, node.right)\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    predictions = []\n",
        "\n",
        "    for row in X:\n",
        "      prediction = self._predict_traverse(row, self.root)\n",
        "      predictions.append(prediction)\n",
        "    return np.array(predictions)\n"
      ],
      "metadata": {
        "id": "cqSt4AWMkXPD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cl = DecisionTreeCl(4)\n",
        "model_cl.fit(X, y)"
      ],
      "metadata": {
        "id": "W6ELn-aGy3ej"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_test = X_train.to_numpy()[100:]\n",
        "# y_test = y_train.to_numpy()[100:]\n",
        "preds = model_cl.predict(X_test)"
      ],
      "metadata": {
        "id": "HMjZtFPRJbUp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubTgYtcQZraZ",
        "outputId": "8ec4261c-0d32-481a-ba20-b3805f44d926"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
              "       0, 1, 1, 2, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwc1IwWdZrTG",
        "outputId": "7853a030-7782-44d2-eaa5-fe87047187de"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
              "       0, 1, 2, 2, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(preds == y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDCOTitOZq8L",
        "outputId": "6cee560c-b3e5-4685-fd89-253249835ee7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.98"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat GTP generation"
      ],
      "metadata": {
        "id": "EUidIV01wYKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = {}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y, depth=0)\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for sample in X:\n",
        "            predictions.append(self._traverse_tree(sample, self.tree))\n",
        "        return predictions\n",
        "\n",
        "    def _build_tree(self, X, y, depth):\n",
        "        # Base cases\n",
        "        if self._should_stop(X, y, depth):\n",
        "            return self._leaf_node(y)\n",
        "\n",
        "        # Find the best split point\n",
        "        best_split = self._find_best_split(X, y)\n",
        "\n",
        "        # Create a new internal node\n",
        "        node = {\n",
        "            'feature_index': best_split['feature_index'],\n",
        "            'threshold': best_split['threshold'],\n",
        "            'left': self._build_tree(best_split['left_X'], best_split['left_y'], depth + 1),\n",
        "            'right': self._build_tree(best_split['right_X'], best_split['right_y'], depth + 1)\n",
        "        }\n",
        "\n",
        "        return node\n",
        "\n",
        "    def _should_stop(self, X, y, depth):\n",
        "        # Stop if maximum depth reached\n",
        "        if self.max_depth is not None and depth >= self.max_depth:\n",
        "            return True\n",
        "\n",
        "        # Stop if all samples have the same class\n",
        "        return len(set(y)) == 1\n",
        "\n",
        "    def _leaf_node(self, y):\n",
        "        # Create a leaf node with the majority class\n",
        "        counts = {}\n",
        "        for label in y:\n",
        "            if label in counts:\n",
        "                counts[label] += 1\n",
        "            else:\n",
        "                counts[label] = 1\n",
        "        majority_class = max(counts, key=counts.get)\n",
        "        return {'class': majority_class}\n",
        "\n",
        "    def _find_best_split(self, X, y):\n",
        "        best_gini = float('inf')\n",
        "        best_split = None\n",
        "\n",
        "        for feature_index in range(len(X[0])):\n",
        "            feature_values = set([sample[feature_index] for sample in X])\n",
        "\n",
        "            for threshold in feature_values:\n",
        "                left_X, left_y, right_X, right_y = self._split_dataset(X, y, feature_index, threshold)\n",
        "                gini = self._calculate_gini(left_y, right_y)\n",
        "\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_split = {\n",
        "                        'feature_index': feature_index,\n",
        "                        'threshold': threshold,\n",
        "                        'left_X': left_X,\n",
        "                        'left_y': left_y,\n",
        "                        'right_X': right_X,\n",
        "                        'right_y': right_y\n",
        "                    }\n",
        "\n",
        "        return best_split\n",
        "\n",
        "    def _split_dataset(self, X, y, feature_index, threshold):\n",
        "        left_X, left_y, right_X, right_y = [], [], [], []\n",
        "\n",
        "        for i in range(len(X)):\n",
        "            if X[i][feature_index] <= threshold:\n",
        "                left_X.append(X[i])\n",
        "                left_y.append(y[i])\n",
        "            else:\n",
        "                right_X.append(X[i])\n",
        "                right_y.append(y[i])\n",
        "\n",
        "        return left_X, left_y, right_X, right_y\n",
        "\n",
        "    def _calculate_gini(self, left_y, right_y):\n",
        "        total_samples = len(left_y) + len(right_y)\n",
        "        gini_left = self._calculate_gini_impurity(left_y)\n",
        "        gini_right = self._calculate_gini_impurity(right_y)\n",
        "        weighted_gini = (len(left_y) / total_samples) * gini_left + (len(right_y) / total_samples) * gini_right\n",
        "        return weighted_gini\n",
        "\n",
        "    def _calculate_gini_impurity(self, y):\n",
        "        counts = {}\n",
        "        for label in y:\n",
        "            if label in counts:\n",
        "                counts[label] += 1\n",
        "            else:\n",
        "                counts[label] = 1\n",
        "        gini_impurity = 1.0\n",
        "        for label in counts:\n",
        "            probability = counts[label] / len(y)\n",
        "            gini_impurity -= probability ** 2\n",
        "        return gini_impurity\n",
        "\n",
        "    def _traverse_tree(self, sample, node):\n",
        "        if 'class' in node:\n",
        "            return node['class']\n",
        "\n",
        "        if sample[node['feature_index']] <= node['threshold']:\n",
        "            return self._traverse_tree(sample, node['left'])\n",
        "        else:\n",
        "            return self._traverse_tree(sample, node['right'])\n"
      ],
      "metadata": {
        "id": "jmVtoD9Ewau_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTree(max_depth=3)\n",
        "tree.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "predictions = tree.predict(X_test)\n",
        "print(predictions) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2xTUsSRwbKP",
        "outputId": "55ed2dc6-5ec4-4494-f560-8ca0fec3e4ec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 1, 2, 1, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k46vf37Uwi9W",
        "outputId": "c2820d7a-a286-4eb0-8d41-88c9fdd2ae06"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
              "       0, 1, 2, 2, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat GTP (recursion)"
      ],
      "metadata": {
        "id": "x51JLbT6JjvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y, depth=0)\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for sample in X:\n",
        "            predictions.append(self._traverse_tree(sample, self.tree))\n",
        "        return predictions\n",
        "\n",
        "    def _build_tree(self, X, y, depth, node=None):\n",
        "        if self._should_stop(X, y, depth):\n",
        "            class_label = self._get_majority_class(y)\n",
        "            return Node(class_label=class_label)\n",
        "\n",
        "        if node is None:\n",
        "            node = Node()\n",
        "\n",
        "        best_split = self._find_best_split(X, y)\n",
        "\n",
        "        left_X, left_y, right_X, right_y = self._split_dataset(X, y, best_split['feature_index'], best_split['threshold'])\n",
        "\n",
        "        node.feature_index = best_split['feature_index']\n",
        "        node.threshold = best_split['threshold']\n",
        "        node.left = self._build_tree(left_X, left_y, depth + 1, Node())\n",
        "        node.right = self._build_tree(right_X, right_y, depth + 1, Node())\n",
        "\n",
        "        return node\n",
        "\n",
        "    def _should_stop(self, X, y, depth):\n",
        "        if self.max_depth is not None and depth >= self.max_depth:\n",
        "            return True\n",
        "        return len(np.unique(y)) == 1\n",
        "\n",
        "    def _get_majority_class(self, y):\n",
        "        unique_classes, class_counts = np.unique(y, return_counts=True)\n",
        "        majority_class = unique_classes[np.argmax(class_counts)]\n",
        "        return majority_class\n",
        "\n",
        "    def _find_best_split(self, X, y):\n",
        "        best_gini = float('inf')\n",
        "        best_split = {}\n",
        "\n",
        "        for feature_index in range(X.shape[1]):\n",
        "            feature_values = np.unique(X[:, feature_index])\n",
        "\n",
        "            for threshold in feature_values:\n",
        "                left_X, left_y, right_X, right_y = self._split_dataset(X, y, feature_index, threshold)\n",
        "                gini = self._calculate_gini(left_y, right_y)\n",
        "\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_split = {\n",
        "                        'feature_index': feature_index,\n",
        "                        'threshold': threshold,\n",
        "                        'left_X': left_X,\n",
        "                        'left_y': left_y,\n",
        "                        'right_X': right_X,\n",
        "                        'right_y': right_y\n",
        "                    }\n",
        "\n",
        "        return best_split\n",
        "\n",
        "    def _split_dataset(self, X, y, feature_index, threshold):\n",
        "        left_mask = X[:, feature_index] <= threshold\n",
        "        right_mask = X[:, feature_index] > threshold\n",
        "        left_X, left_y = X[left_mask], y[left_mask]\n",
        "        right_X, right_y = X[right_mask], y[right_mask]\n",
        "        return left_X, left_y, right_X, right_y\n",
        "\n",
        "    def _calculate_gini(self, left_y, right_y):\n",
        "        total_samples = len(left_y) + len(right_y)\n",
        "        gini_left = self._calculate_gini_impurity(left_y)\n",
        "        gini_right = self._calculate_gini_impurity(right_y)\n",
        "        weighted_gini = (len(left_y) / total_samples) * gini_left + (len(right_y) / total_samples) * gini_right\n",
        "        return weighted_gini\n",
        "\n",
        "    def _calculate_gini_impurity(self, y):\n",
        "        unique_classes, class_counts = np.unique(y, return_counts=True)\n",
        "        class_probabilities = class_counts / len(y)\n",
        "        gini_impurity = 1.0 - np.sum(class_probabilities**2)\n",
        "        return gini_impurity\n",
        "\n",
        "    def _traverse_tree(self, sample, node):\n",
        "        if node.class_label is not None:\n",
        "            return node.class_label\n",
        "\n",
        "        if sample[node.feature_index] <= node.threshold:\n",
        "            return self._traverse_tree(sample, node.left)\n",
        "        else:\n",
        "            return self._traverse_tree(sample, node.right)\n",
        "\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, class_label=None):\n",
        "        self.feature_index = feature_index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.class_label = class_label\n"
      ],
      "metadata": {
        "id": "ebG7BykM-7zA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTree(max_depth=3)\n",
        "tree.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "predictions = tree.predict(X_test)\n",
        "print(np.array(predictions))\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKU6IXi1P5yS",
        "outputId": "c813b209-009d-40ce-8b92-e60cf66ac082"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
            " 0 0 0 2 1 1 0 0 1 1 2 1 2]\n",
            "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
            " 0 0 0 2 1 1 0 0 1 2 2 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UCX_F08oQCMA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}